# ROCmLibs-Fallback
ROCm rocBLAS Library With Tensile Fallback

# Supported GPU Architectures
gfx803

gfx900

gfx906

gfx1010

gfx1011

gfx1012

gfx1030

gfx1031

gfx1100

gfx1101

gfx1102

# Build
This library is built with default parameters. 

If you want to build by yourself, Here are two references.

1. [Guide: build llama.cpp on windows with AMD GPUs, and using ROCm](https://www.reddit.com/r/LocalLLaMA/comments/16d1hi0/guide_build_llamacpp_on_windows_with_amd_gpus_and/)

2. [6600/6600 XT/6650 XT gfx1032 libraries for compilation of Kobold.cpp](https://github.com/LostRuins/koboldcpp/issues/655)
